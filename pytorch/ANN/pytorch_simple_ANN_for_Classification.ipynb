{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a8e6a65",
   "metadata": {},
   "source": [
    "A simple walkthrough of how to code a fully connected neural network\n",
    "using the PyTorch library. For demonstration we train it on the very\n",
    "common MNIST dataset of handwritten digits. In this code we go through\n",
    "how to create the network as well as initialize a loss function, optimizer,\n",
    "check accuracy and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9020e9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066c266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb850ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a simple fully connected nural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634543f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size, output_classes):\n",
    "        super(ANN, self).__init__()\n",
    "        \n",
    "        #First fully connected layer\n",
    "        self.first_fc_layer = nn.Linear(input_size, 50)\n",
    "        self.second_fc_layer = nn.Linear(50, output_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #Pass through first layer\n",
    "        x = F.relu(self.first_fc_layer(x))\n",
    "        \n",
    "        #output layer\n",
    "        x = self.second_fc_layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf0f47bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "976f1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
    "device = torch.device( \"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45039048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3bcc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = 784\n",
    "output_classes = 10\n",
    "learning_rate = 0.001\n",
    "batch_size = 64\n",
    "num_epoch = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05af7b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "138f8096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "train_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
    ")\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81772593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialized Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19e3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN(input_size = input_shape, output_classes = output_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27e39aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3843b072",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6baa9bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d8a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "354770c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "385ed780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "====================================================================================================\n",
      "Epoch 0 is Completed.\n",
      "------------------------------------------------------------\n",
      "Epoch 1 is Completed.\n",
      "------------------------------------------------------------\n",
      "Epoch 2 is Completed.\n",
      "------------------------------------------------------------\n",
      "Epoch 3 is Completed.\n",
      "------------------------------------------------------------\n",
      "Epoch 4 is Completed.\n",
      "------------------------------------------------------------\n",
      "Training Completed\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# lists to store train and test accuracy\n",
    "print(\"Starting Training\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # Get data to cuda if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        # Get to correct shape\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # Forward\n",
    "        scores = model(data)\n",
    "        loss = criterion(scores, targets)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient descent or adam step\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch} is Completed.\")\n",
    "    print(\"-\"*60)\n",
    "print(\"Training Completed\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d89d338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48a2335f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
    "    with torch.no_grad():\n",
    "        # Loop through the data\n",
    "        for x, y in loader:\n",
    "\n",
    "            # Move data to device\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Get to correct shape\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "\n",
    "            # Check how many we got correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "\n",
    "            # Keep track of number of samples\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "    model.train()\n",
    "    return num_correct / num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea04a166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 97.25\n",
      "Accuracy on test set: 96.31\n"
     ]
    }
   ],
   "source": [
    "# Check accuracy on training & test to see how good our model\n",
    "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
    "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ee9f30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
